{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/profiles.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove unneeded variables\n",
    "\n",
    "First, let's drop all the columns we won't use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['last_online', 'location', 'sign'], axis=1, inplace=True)\n",
    "df.drop([f\"essay{n}\" for n in np.arange(0,10)], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactor \"diet\" variable\n",
    "\n",
    "The \"diet\" variable has 6 possible cuisines (anything, vegetarian, vegan, kosher, halal, and other) and 2 changers (mostly/strictly), which might create unnecessary dummy variables that won't add value to the model. So let's boil it down to diet type without the nuance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, subset=['diet'], inplace=True)\n",
    "df['vegetarian'] = df['diet'].apply(lambda x: 1 if (\"vegetarian\" in x) or (\"vegan\" in x) else 0)\n",
    "df.drop(\"diet\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse spoken languages\n",
    "\n",
    "The same goes for the `language` variable. There are 3 modifiers for a multitude of languages. The permutation between all possible values will generate thousands of unnecessary columns. Let's just keep the languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                            english\n",
       "1                           english, spanish, french\n",
       "2                               english, french, c++\n",
       "3                                    english, german\n",
       "5                                   english, chinese\n",
       "                            ...                     \n",
       "59936                               english, chinese\n",
       "59937                               english, spanish\n",
       "59942                                        english\n",
       "59943                                        english\n",
       "59944    english, spanish, chinese, korean, japanese\n",
       "Name: speaks, Length: 35551, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['speaks'].replace([\" \\(fluently\\)\", \" \\(okay\\)\", \" \\(poorly\\)\"], \"\", regex=True, inplace=True)\n",
    "df[\"speaks\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But filtering out the language modifiers isn't enough. There's only one column for all the user's spoken languages, whose combination might generate a dozen thousands dummy variables. Therefore, each `speaks` value should be parsed and gain a dummy variable of its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_to_dummies(df, column):\n",
    "    \"\"\"\n",
    "    Transforms a column with comma-separated values into new 0-or-1 columns.\n",
    "    \"\"\"\n",
    "    expanded_values = df[column].str.split(pat=\", \", expand=True)\n",
    "    # see https://stackoverflow.com/questions/26977076/pandas-unique-values-multiple-columns \n",
    "    unique_labels = pd.unique(expanded_values.values.ravel('K'))\n",
    "    for label in unique_labels:\n",
    "        if label == None:\n",
    "            label = \"None\"\n",
    "        df[f\"{column}_{label}\"] = df[column].apply(lambda x: 1 if label in x else 0)\n",
    "    df.drop(column, axis=1, inplace=True)\n",
    "    df.drop(f\"{column}_None\", axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "df.dropna(axis=0, subset=[\"speaks\"], inplace=True)\n",
    "df = parse_to_dummies(df, column=\"speaks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert \"drink\" values into a numerical scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2.0\n",
       "1        3.0\n",
       "2        2.0\n",
       "3        2.0\n",
       "5        2.0\n",
       "        ... \n",
       "59936    2.0\n",
       "59937    2.0\n",
       "59942    3.0\n",
       "59943    0.0\n",
       "59944    2.0\n",
       "Name: drinks, Length: 35530, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['drinks'].replace({\"not at all\": 0,\n",
    "                     \"rarely\": 1,\n",
    "                     \"socially\": 2,\n",
    "                     \"often\": 3,\n",
    "                     \"very often\": 4,\n",
    "                     \"desperately\": 5}, inplace=True)\n",
    "df['drinks']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract offspring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['offspring'].replace(['doesn&rsquo;t have kids',\n",
    "                         'doesn&rsquo;t have kids, and doesn&rsquo;t want any',\n",
    "                         'doesn&rsquo;t have kids, but might want them',\n",
    "                         'doesn&rsquo;t have kids, but wants them',\n",
    "                         'might want kids',\n",
    "                         'doesn&rsquo;t want kids',\n",
    "                         'wants kids'], 0, inplace=True)\n",
    "\n",
    "df['offspring'].replace(['has a kid',\n",
    "                         'has a kid, and might want more',\n",
    "                         'has a kid, and wants more',\n",
    "                         'has a kid, but doesn&rsquo;t want more',\n",
    "                         'has kids',\n",
    "                         'has kids, and might want more',\n",
    "                         'has kids, and wants more',\n",
    "                         'has kids, but doesn&rsquo;t want more',], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract ethnicities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, subset=['ethnicity'], inplace=True)\n",
    "df = parse_to_dummies(df, column=\"ethnicity\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up religion\n",
    "\n",
    "Let's remove the religion variable modifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['religion'].replace([\" and laughing about it\",\n",
    "                       \" and somewhat serious about it\",\n",
    "                       \" and very serious about it\",\n",
    "                       \" but not too serious about it\"], \"\", regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         agnosticism\n",
       "1         agnosticism\n",
       "3                 NaN\n",
       "5             atheism\n",
       "6                 NaN\n",
       "             ...     \n",
       "59936         atheism\n",
       "59937         judaism\n",
       "59942     agnosticism\n",
       "59943    christianity\n",
       "59944     agnosticism\n",
       "Name: religion, Length: 32805, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['religion']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract pet information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pets\"].fillna(\"Unknown\", inplace=True)\n",
    "df['dog_person'] = df['pets'].apply(lambda x: 1 if (\"has dogs\" in x) or (\"likes dogs\" in x) else 0)\n",
    "df['cat_person'] = df['pets'].apply(lambda x: 1 if (\"has cats\" in x) or (\"likes cats\" in x) else 0)\n",
    "df.drop('pets', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dummy variables from categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy(df):\n",
    "    \"\"\"\n",
    "    Creates dummy variables for all the categorial variables in a DataFrame and concatenates it\n",
    "    with the original numerical columns.\n",
    "    Input: pandas DataFrame\n",
    "    Output: pandas DataFrame\n",
    "    \"\"\"\n",
    "    cat_cols = df.select_dtypes(include=\"object\").columns\n",
    "    num_cols = df.select_dtypes(exclude=\"object\").columns\n",
    "    dummy_df = pd.get_dummies(df[cat_cols],\n",
    "                              prefix=cat_cols,\n",
    "                              prefix_sep=\"_\",\n",
    "                              dummy_na=True,\n",
    "                              columns=cat_cols)\n",
    "                              \n",
    "    df_new = pd.concat([df[num_cols], dummy_df], axis=1)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_dummy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>drinks</th>\n",
       "      <th>height</th>\n",
       "      <th>income</th>\n",
       "      <th>offspring</th>\n",
       "      <th>vegetarian</th>\n",
       "      <th>speaks_english</th>\n",
       "      <th>speaks_spanish</th>\n",
       "      <th>speaks_french</th>\n",
       "      <th>speaks_german</th>\n",
       "      <th>...</th>\n",
       "      <th>smokes_trying to quit</th>\n",
       "      <th>smokes_when drinking</th>\n",
       "      <th>smokes_yes</th>\n",
       "      <th>smokes_nan</th>\n",
       "      <th>status_available</th>\n",
       "      <th>status_married</th>\n",
       "      <th>status_seeing someone</th>\n",
       "      <th>status_single</th>\n",
       "      <th>status_unknown</th>\n",
       "      <th>status_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32</td>\n",
       "      <td>2.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59936</th>\n",
       "      <td>25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59937</th>\n",
       "      <td>32</td>\n",
       "      <td>2.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59942</th>\n",
       "      <td>24</td>\n",
       "      <td>3.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59943</th>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59944</th>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32805 rows × 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  drinks  height  income  offspring  vegetarian  speaks_english  \\\n",
       "0       22     2.0    75.0      -1        0.0           0               1   \n",
       "1       35     3.0    70.0   80000        0.0           0               1   \n",
       "3       23     2.0    71.0   20000        0.0           1               1   \n",
       "5       29     2.0    67.0      -1        0.0           0               1   \n",
       "6       32     2.0    65.0      -1        NaN           0               1   \n",
       "...    ...     ...     ...     ...        ...         ...             ...   \n",
       "59936   25     2.0    61.0      -1        0.0           0               1   \n",
       "59937   32     2.0    69.0      -1        NaN           0               1   \n",
       "59942   24     3.0    72.0      -1        0.0           0               1   \n",
       "59943   42     0.0    71.0  100000        0.0           0               1   \n",
       "59944   27     2.0    73.0      -1        0.0           0               1   \n",
       "\n",
       "       speaks_spanish  speaks_french  speaks_german  ...  \\\n",
       "0                   0              0              0  ...   \n",
       "1                   1              1              0  ...   \n",
       "3                   0              0              1  ...   \n",
       "5                   0              0              0  ...   \n",
       "6                   0              0              0  ...   \n",
       "...               ...            ...            ...  ...   \n",
       "59936               0              0              0  ...   \n",
       "59937               1              0              0  ...   \n",
       "59942               0              0              0  ...   \n",
       "59943               0              0              0  ...   \n",
       "59944               1              0              0  ...   \n",
       "\n",
       "       smokes_trying to quit  smokes_when drinking  smokes_yes  smokes_nan  \\\n",
       "0                          0                     0           0           0   \n",
       "1                          0                     0           0           0   \n",
       "3                          0                     0           0           0   \n",
       "5                          0                     0           0           0   \n",
       "6                          0                     0           0           1   \n",
       "...                      ...                   ...         ...         ...   \n",
       "59936                      0                     0           0           0   \n",
       "59937                      0                     0           0           0   \n",
       "59942                      0                     0           0           0   \n",
       "59943                      0                     0           0           0   \n",
       "59944                      1                     0           0           0   \n",
       "\n",
       "       status_available  status_married  status_seeing someone  status_single  \\\n",
       "0                     0               0                      0              1   \n",
       "1                     0               0                      0              1   \n",
       "3                     0               0                      0              1   \n",
       "5                     0               0                      0              1   \n",
       "6                     0               0                      0              1   \n",
       "...                 ...             ...                    ...            ...   \n",
       "59936                 0               0                      0              1   \n",
       "59937                 0               0                      0              1   \n",
       "59942                 0               0                      0              1   \n",
       "59943                 0               0                      0              1   \n",
       "59944                 0               0                      0              1   \n",
       "\n",
       "       status_unknown  status_nan  \n",
       "0                   0           0  \n",
       "1                   0           0  \n",
       "3                   0           0  \n",
       "5                   0           0  \n",
       "6                   0           0  \n",
       "...               ...         ...  \n",
       "59936               0           0  \n",
       "59937               0           0  \n",
       "59942               0           0  \n",
       "59943               0           0  \n",
       "59944               0           0  \n",
       "\n",
       "[32805 rows x 195 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_table = df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16743174679874365"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['offspring'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "drinks\n",
      "height\n",
      "income\n",
      "offspring\n",
      "vegetarian\n",
      "speaks_english\n",
      "speaks_spanish\n",
      "speaks_french\n",
      "speaks_german\n",
      "speaks_chinese\n",
      "speaks_sign language\n",
      "speaks_tagalog\n",
      "speaks_other\n",
      "speaks_indonesian\n",
      "speaks_swedish\n",
      "speaks_belarusan\n",
      "speaks_japanese\n",
      "speaks_farsi\n",
      "speaks_hindi\n",
      "speaks_afrikaans\n",
      "speaks_c++\n",
      "speaks_russian\n",
      "speaks_polish\n",
      "speaks_croatian\n",
      "speaks_italian\n",
      "speaks_vietnamese\n",
      "speaks_portuguese\n",
      "speaks_latin\n",
      "speaks_czech\n",
      "speaks_greek\n",
      "speaks_norwegian\n",
      "speaks_hebrew\n",
      "speaks_korean\n",
      "speaks_esperanto\n",
      "speaks_tibetan\n",
      "speaks_thai\n",
      "speaks_swahili\n",
      "speaks_turkish\n",
      "speaks_tamil\n",
      "speaks_lisp\n",
      "speaks_sanskrit\n",
      "speaks_arabic\n",
      "speaks_hungarian\n",
      "speaks_urdu\n",
      "speaks_romanian\n",
      "speaks_finnish\n",
      "speaks_bulgarian\n",
      "speaks_yiddish\n",
      "speaks_dutch\n",
      "speaks_irish\n",
      "speaks_persian\n",
      "speaks_gujarati\n",
      "speaks_khmer\n",
      "speaks_hawaiian\n",
      "speaks_danish\n",
      "speaks_cebuano\n",
      "speaks_ilongo\n",
      "speaks_icelandic\n",
      "speaks_serbian\n",
      "speaks_ancient greek\n",
      "speaks_albanian\n",
      "speaks_catalan\n",
      "speaks_occitan\n",
      "speaks_mongolian\n",
      "speaks_malay\n",
      "speaks_rotuman\n",
      "speaks_bengali\n",
      "speaks_slovak\n",
      "speaks_georgian\n",
      "speaks_latvian\n",
      "speaks_lithuanian\n",
      "speaks_estonian\n",
      "speaks_welsh\n",
      "speaks_maori\n",
      "speaks_basque\n",
      "speaks_ukrainian\n",
      "speaks_frisian\n",
      "speaks_armenian\n",
      "speaks_chechen\n",
      "speaks_slovenian\n",
      "speaks_breton\n",
      "speaks_sardinian\n",
      "ethnicity_asian\n",
      "ethnicity_white\n",
      "ethnicity_hispanic / latin\n",
      "ethnicity_pacific islander\n",
      "ethnicity_black\n",
      "ethnicity_middle eastern\n",
      "ethnicity_native american\n",
      "ethnicity_indian\n",
      "ethnicity_other\n",
      "dog_person\n",
      "cat_person\n",
      "body_type_a little extra\n",
      "body_type_athletic\n",
      "body_type_average\n",
      "body_type_curvy\n",
      "body_type_fit\n",
      "body_type_full figured\n",
      "body_type_jacked\n",
      "body_type_overweight\n",
      "body_type_rather not say\n",
      "body_type_skinny\n",
      "body_type_thin\n",
      "body_type_used up\n",
      "body_type_nan\n",
      "drugs_never\n",
      "drugs_often\n",
      "drugs_sometimes\n",
      "drugs_nan\n",
      "education_college/university\n",
      "education_dropped out of college/university\n",
      "education_dropped out of high school\n",
      "education_dropped out of law school\n",
      "education_dropped out of masters program\n",
      "education_dropped out of med school\n",
      "education_dropped out of ph.d program\n",
      "education_dropped out of space camp\n",
      "education_dropped out of two-year college\n",
      "education_graduated from college/university\n",
      "education_graduated from high school\n",
      "education_graduated from law school\n",
      "education_graduated from masters program\n",
      "education_graduated from med school\n",
      "education_graduated from ph.d program\n",
      "education_graduated from space camp\n",
      "education_graduated from two-year college\n",
      "education_high school\n",
      "education_law school\n",
      "education_masters program\n",
      "education_med school\n",
      "education_ph.d program\n",
      "education_space camp\n",
      "education_two-year college\n",
      "education_working on college/university\n",
      "education_working on high school\n",
      "education_working on law school\n",
      "education_working on masters program\n",
      "education_working on med school\n",
      "education_working on ph.d program\n",
      "education_working on space camp\n",
      "education_working on two-year college\n",
      "education_nan\n",
      "job_artistic / musical / writer\n",
      "job_banking / financial / real estate\n",
      "job_clerical / administrative\n",
      "job_computer / hardware / software\n",
      "job_construction / craftsmanship\n",
      "job_education / academia\n",
      "job_entertainment / media\n",
      "job_executive / management\n",
      "job_hospitality / travel\n",
      "job_law / legal services\n",
      "job_medicine / health\n",
      "job_military\n",
      "job_other\n",
      "job_political / government\n",
      "job_rather not say\n",
      "job_retired\n",
      "job_sales / marketing / biz dev\n",
      "job_science / tech / engineering\n",
      "job_student\n",
      "job_transportation\n",
      "job_unemployed\n",
      "job_nan\n",
      "orientation_bisexual\n",
      "orientation_gay\n",
      "orientation_straight\n",
      "orientation_nan\n",
      "religion_agnosticism\n",
      "religion_atheism\n",
      "religion_buddhism\n",
      "religion_catholicism\n",
      "religion_christianity\n",
      "religion_hinduism\n",
      "religion_islam\n",
      "religion_judaism\n",
      "religion_other\n",
      "religion_nan\n",
      "sex_f\n",
      "sex_m\n",
      "sex_nan\n",
      "smokes_no\n",
      "smokes_sometimes\n",
      "smokes_trying to quit\n",
      "smokes_when drinking\n",
      "smokes_yes\n",
      "smokes_nan\n",
      "status_available\n",
      "status_married\n",
      "status_seeing someone\n",
      "status_single\n",
      "status_unknown\n",
      "status_nan\n"
     ]
    }
   ],
   "source": [
    "for x in df.columns:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                          25.717557\n",
       "drinks                        2.533074\n",
       "height                       69.423664\n",
       "income                   102289.511450\n",
       "offspring                     0.085714\n",
       "                             ...      \n",
       "status_married                0.003817\n",
       "status_seeing someone         0.041985\n",
       "status_single                 0.904580\n",
       "status_unknown                0.000000\n",
       "status_nan                    0.000000\n",
       "Length: 195, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['drugs_often'] == 1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    27747\n",
       "1     5058\n",
       "Name: vegetarian, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vegetarian'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
