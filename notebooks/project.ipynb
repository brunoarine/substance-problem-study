{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/profiles.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove unneeded variables\n",
    "\n",
    "First, let's drop all the columns we won't use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['last_online', 'location', 'sign'], axis=1, inplace=True)\n",
    "df.drop([f\"essay{n}\" for n in np.arange(0,10)], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactor \"diet\" variable\n",
    "\n",
    "The \"diet\" variable has 6 possible cuisines (anything, vegetarian, vegan, kosher, halal, and other) and 2 changers (mostly/strictly), which might create unnecessary dummy variables that won't add value to the model. So let's boil it down to diet type without the nuance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          anything\n",
       "1             other\n",
       "2          anything\n",
       "3        vegetarian\n",
       "4               NaN\n",
       "            ...    \n",
       "59941           NaN\n",
       "59942      anything\n",
       "59943      anything\n",
       "59944      anything\n",
       "59945           NaN\n",
       "Name: diet, Length: 59946, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diet'].replace([\"mostly \", \"strictly \"], \"\", regex=True, inplace=True)\n",
    "df['diet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse spoken languages\n",
    "\n",
    "The same goes for the `language` variable. There are 3 modifiers for a multitude of languages. The permutation between all possible values will generate thousands of unnecessary columns. Let's just keep the languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                            english\n",
       "1                           english, spanish, french\n",
       "2                               english, french, c++\n",
       "3                                    english, german\n",
       "4                                            english\n",
       "                            ...                     \n",
       "59941                                        english\n",
       "59942                                        english\n",
       "59943                                        english\n",
       "59944    english, spanish, chinese, korean, japanese\n",
       "59945                                        english\n",
       "Name: speaks, Length: 59946, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['speaks'].replace([\" \\(fluently\\)\", \" \\(okay\\)\", \" \\(poorly\\)\"], \"\", regex=True, inplace=True)\n",
    "df[\"speaks\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But filtering out the language modifiers isn't enough. There's only one column for all the user's spoken languages, whose combination might generate a dozen thousands dummy variables. Therefore, each `speaks` value should be parsed and gain a dummy variable of its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_to_dummies(df, column):\n",
    "    \"\"\"\n",
    "    Transforms a column with comma-separated values into new 0-or-1 columns.\n",
    "    \"\"\"\n",
    "    expanded_values = df[column].str.split(pat=\", \", expand=True)\n",
    "    # see https://stackoverflow.com/questions/26977076/pandas-unique-values-multiple-columns \n",
    "    unique_labels = pd.unique(expanded_values.values.ravel('K'))\n",
    "    table_shape = (df.shape[0], len(unique_labels))\n",
    "    dummy_table = pd.DataFrame(np.zeros(table_shape, dtype=\"int\"),\n",
    "                              columns=[f\"{column}_{label}\" for label in unique_labels])\n",
    "    for index,row in expanded_values.iterrows():\n",
    "        for item in row:\n",
    "            dummy_table.at[index, f\"{column}_{item}\"] = 1\n",
    "   \n",
    "    dummy_table.drop([f\"{column}_None\"], axis=1, inplace=True)\n",
    "    df_drop_column = df.drop(column, axis=1)\n",
    "    return pd.concat([df_drop_column, dummy_table], axis=1)\n",
    "\n",
    "df = parse_to_dummies(df, column=\"speaks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert \"drink\" values into a numerical scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2.0\n",
       "1        3.0\n",
       "2        2.0\n",
       "3        2.0\n",
       "4        2.0\n",
       "        ... \n",
       "59941    2.0\n",
       "59942    3.0\n",
       "59943    0.0\n",
       "59944    2.0\n",
       "59945    2.0\n",
       "Name: drinks, Length: 59946, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['drinks'].replace({\"not at all\": 0,\n",
    "                     \"rarely\": 1,\n",
    "                     \"socially\": 2,\n",
    "                     \"often\": 3,\n",
    "                     \"very often\": 4,\n",
    "                     \"desperately\": 5}, inplace=True)\n",
    "df['drinks']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract offspring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['offspring'].replace(['doesn&rsquo;t have kids',\n",
    "                         'doesn&rsquo;t have kids, and doesn&rsquo;t want any',\n",
    "                         'doesn&rsquo;t have kids, but might want them',\n",
    "                         'doesn&rsquo;t have kids, but wants them',\n",
    "                         'might want kids',\n",
    "                         'doesn&rsquo;t want kids',\n",
    "                         'wants kids'], 0, inplace=True)\n",
    "\n",
    "df['offspring'].replace(['has a kid',\n",
    "                         'has a kid, and might want more',\n",
    "                         'has a kid, and wants more',\n",
    "                         'has a kid, but doesn&rsquo;t want more',\n",
    "                         'has kids',\n",
    "                         'has kids, and might want more',\n",
    "                         'has kids, and wants more',\n",
    "                         'has kids, but doesn&rsquo;t want more',], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract ethnicities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = parse_to_dummies(df, column=\"ethnicity\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up religion\n",
    "\n",
    "Let's remove the religion variable modifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['religion'].replace([\" and laughing about it\",\n",
    "                       \" somewhat serious about it\",\n",
    "                       \" and very serious about it\",\n",
    "                       \" but not too serious about it\"], \"\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract pet information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pets\"].fillna(\"Unknown\", inplace=True)\n",
    "df['dog_person'] = df['pets'].apply(lambda x: 1 if (\"has dogs\" in x) or (\"likes dogs\" in x) else 0)\n",
    "df['cat_person'] = df['pets'].apply(lambda x: 1 if (\"has cats\" in x) or (\"likes cats\" in x) else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dummy variables from categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy(df):\n",
    "    \"\"\"\n",
    "    Creates dummy variables for all the categorial variables in a DataFrame and concatenates it\n",
    "    with the original numerical columns.\n",
    "    Input: pandas DataFrame\n",
    "    Output: pandas DataFrame\n",
    "    \"\"\"\n",
    "    cat_cols = df.select_dtypes(include=\"object\").columns\n",
    "    num_cols = df.select_dtypes(exclude=\"object\").columns\n",
    "    dummy_df = pd.get_dummies(df[cat_cols],\n",
    "                              prefix=cat_cols,\n",
    "                              prefix_sep=\"_\",\n",
    "                              dummy_na=True,\n",
    "                              columns=cat_cols)\n",
    "                              \n",
    "    df_new = pd.concat([df[num_cols], dummy_df], axis=1)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>drinks</th>\n",
       "      <th>height</th>\n",
       "      <th>income</th>\n",
       "      <th>offspring</th>\n",
       "      <th>speaks_english</th>\n",
       "      <th>speaks_nan</th>\n",
       "      <th>speaks_afrikaans</th>\n",
       "      <th>speaks_french</th>\n",
       "      <th>speaks_portuguese</th>\n",
       "      <th>...</th>\n",
       "      <th>smokes_trying to quit</th>\n",
       "      <th>smokes_when drinking</th>\n",
       "      <th>smokes_yes</th>\n",
       "      <th>smokes_nan</th>\n",
       "      <th>status_available</th>\n",
       "      <th>status_married</th>\n",
       "      <th>status_seeing someone</th>\n",
       "      <th>status_single</th>\n",
       "      <th>status_unknown</th>\n",
       "      <th>status_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>2.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 502 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  drinks  height  income  offspring  speaks_english  speaks_nan  \\\n",
       "0   22     2.0    75.0      -1        0.0               1           0   \n",
       "1   35     3.0    70.0   80000        0.0               1           0   \n",
       "2   38     2.0    68.0      -1        NaN               1           0   \n",
       "3   23     2.0    71.0   20000        0.0               1           0   \n",
       "4   29     2.0    66.0      -1        NaN               1           0   \n",
       "\n",
       "   speaks_afrikaans  speaks_french  speaks_portuguese  ...  \\\n",
       "0                 0              0                  0  ...   \n",
       "1                 0              1                  0  ...   \n",
       "2                 0              1                  0  ...   \n",
       "3                 0              0                  0  ...   \n",
       "4                 0              0                  0  ...   \n",
       "\n",
       "   smokes_trying to quit  smokes_when drinking  smokes_yes  smokes_nan  \\\n",
       "0                      0                     0           0           0   \n",
       "1                      0                     0           0           0   \n",
       "2                      0                     0           0           0   \n",
       "3                      0                     0           0           0   \n",
       "4                      0                     0           0           0   \n",
       "\n",
       "   status_available  status_married  status_seeing someone  status_single  \\\n",
       "0                 0               0                      0              1   \n",
       "1                 0               0                      0              1   \n",
       "2                 1               0                      0              0   \n",
       "3                 0               0                      0              1   \n",
       "4                 0               0                      0              1   \n",
       "\n",
       "   status_unknown  status_nan  \n",
       "0               0           0  \n",
       "1               0           0  \n",
       "2               0           0  \n",
       "3               0           0  \n",
       "4               0           0  \n",
       "\n",
       "[5 rows x 502 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_dummy(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "drinks\n",
      "height\n",
      "income\n",
      "offspring\n",
      "speaks_english\n",
      "speaks_nan\n",
      "speaks_afrikaans\n",
      "speaks_french\n",
      "speaks_portuguese\n",
      "speaks_spanish\n",
      "speaks_german\n",
      "speaks_chinese\n",
      "speaks_sign language\n",
      "speaks_c++\n",
      "speaks_tagalog\n",
      "speaks_other\n",
      "speaks_russian\n",
      "speaks_dutch\n",
      "speaks_indonesian\n",
      "speaks_swedish\n",
      "speaks_belarusan\n",
      "speaks_japanese\n",
      "speaks_farsi\n",
      "speaks_italian\n",
      "speaks_hindi\n",
      "speaks_polish\n",
      "speaks_korean\n",
      "speaks_czech\n",
      "speaks_croatian\n",
      "speaks_vietnamese\n",
      "speaks_esperanto\n",
      "speaks_latin\n",
      "speaks_greek\n",
      "speaks_norwegian\n",
      "speaks_hebrew\n",
      "speaks_arabic\n",
      "speaks_tibetan\n",
      "speaks_georgian\n",
      "speaks_thai\n",
      "speaks_swahili\n",
      "speaks_khmer\n",
      "speaks_turkish\n",
      "speaks_tamil\n",
      "speaks_lisp\n",
      "speaks_serbian\n",
      "speaks_sanskrit\n",
      "speaks_bengali\n",
      "speaks_catalan\n",
      "speaks_hungarian\n",
      "speaks_irish\n",
      "speaks_urdu\n",
      "speaks_romanian\n",
      "speaks_finnish\n",
      "speaks_bulgarian\n",
      "speaks_ancient greek\n",
      "speaks_yiddish\n",
      "speaks_hawaiian\n",
      "speaks_lithuanian\n",
      "speaks_cebuano\n",
      "speaks_persian\n",
      "speaks_maori\n",
      "speaks_danish\n",
      "speaks_gujarati\n",
      "speaks_albanian\n",
      "speaks_frisian\n",
      "speaks_ilongo\n",
      "speaks_icelandic\n",
      "speaks_slovenian\n",
      "speaks_latvian\n",
      "speaks_occitan\n",
      "speaks_malay\n",
      "speaks_mongolian\n",
      "speaks_rotuman\n",
      "speaks_slovak\n",
      "speaks_ukrainian\n",
      "speaks_armenian\n",
      "speaks_estonian\n",
      "speaks_chechen\n",
      "speaks_welsh\n",
      "speaks_basque\n",
      "speaks_breton\n",
      "speaks_sardinian\n",
      "ethnicity_asian\n",
      "ethnicity_white\n",
      "ethnicity_nan\n",
      "ethnicity_hispanic / latin\n",
      "ethnicity_pacific islander\n",
      "ethnicity_black\n",
      "ethnicity_middle eastern\n",
      "ethnicity_native american\n",
      "ethnicity_indian\n",
      "ethnicity_other\n",
      "body_type_a little extra\n",
      "body_type_athletic\n",
      "body_type_average\n",
      "body_type_curvy\n",
      "body_type_fit\n",
      "body_type_full figured\n",
      "body_type_jacked\n",
      "body_type_overweight\n",
      "body_type_rather not say\n",
      "body_type_skinny\n",
      "body_type_thin\n",
      "body_type_used up\n",
      "body_type_nan\n",
      "diet_anything\n",
      "diet_halal\n",
      "diet_kosher\n",
      "diet_other\n",
      "diet_vegan\n",
      "diet_vegetarian\n",
      "diet_nan\n",
      "drugs_never\n",
      "drugs_often\n",
      "drugs_sometimes\n",
      "drugs_nan\n",
      "education_college/university\n",
      "education_dropped out of college/university\n",
      "education_dropped out of high school\n",
      "education_dropped out of law school\n",
      "education_dropped out of masters program\n",
      "education_dropped out of med school\n",
      "education_dropped out of ph.d program\n",
      "education_dropped out of space camp\n",
      "education_dropped out of two-year college\n",
      "education_graduated from college/university\n",
      "education_graduated from high school\n",
      "education_graduated from law school\n",
      "education_graduated from masters program\n",
      "education_graduated from med school\n",
      "education_graduated from ph.d program\n",
      "education_graduated from space camp\n",
      "education_graduated from two-year college\n",
      "education_high school\n",
      "education_law school\n",
      "education_masters program\n",
      "education_med school\n",
      "education_ph.d program\n",
      "education_space camp\n",
      "education_two-year college\n",
      "education_working on college/university\n",
      "education_working on high school\n",
      "education_working on law school\n",
      "education_working on masters program\n",
      "education_working on med school\n",
      "education_working on ph.d program\n",
      "education_working on space camp\n",
      "education_working on two-year college\n",
      "education_nan\n",
      "job_artistic / musical / writer\n",
      "job_banking / financial / real estate\n",
      "job_clerical / administrative\n",
      "job_computer / hardware / software\n",
      "job_construction / craftsmanship\n",
      "job_education / academia\n",
      "job_entertainment / media\n",
      "job_executive / management\n",
      "job_hospitality / travel\n",
      "job_law / legal services\n",
      "job_medicine / health\n",
      "job_military\n",
      "job_other\n",
      "job_political / government\n",
      "job_rather not say\n",
      "job_retired\n",
      "job_sales / marketing / biz dev\n",
      "job_science / tech / engineering\n",
      "job_student\n",
      "job_transportation\n",
      "job_unemployed\n",
      "job_nan\n",
      "location_alameda, california\n",
      "location_albany, california\n",
      "location_amsterdam, netherlands\n",
      "location_arcadia, california\n",
      "location_asheville, north carolina\n",
      "location_ashland, california\n",
      "location_astoria, new york\n",
      "location_atherton, california\n",
      "location_atlanta, georgia\n",
      "location_austin, texas\n",
      "location_bayshore, california\n",
      "location_bellingham, washington\n",
      "location_bellwood, illinois\n",
      "location_belmont, california\n",
      "location_belvedere tiburon, california\n",
      "location_benicia, california\n",
      "location_berkeley, california\n",
      "location_billings, montana\n",
      "location_boise, idaho\n",
      "location_bolinas, california\n",
      "location_bonaduz, switzerland\n",
      "location_boston, massachusetts\n",
      "location_boulder, colorado\n",
      "location_brea, california\n",
      "location_brisbane, california\n",
      "location_brooklyn, new york\n",
      "location_burlingame, california\n",
      "location_cambridge, massachusetts\n",
      "location_campbell, california\n",
      "location_canyon country, california\n",
      "location_canyon, california\n",
      "location_castro valley, california\n",
      "location_chicago, illinois\n",
      "location_chico, california\n",
      "location_cincinnati, ohio\n",
      "location_colma, california\n",
      "location_columbus, ohio\n",
      "location_concord, california\n",
      "location_cork, ireland\n",
      "location_corte madera, california\n",
      "location_costa mesa, california\n",
      "location_crockett, california\n",
      "location_crowley, texas\n",
      "location_daly city, california\n",
      "location_denver, colorado\n",
      "location_east palo alto, california\n",
      "location_edinburgh, united kingdom\n",
      "location_el cerrito, california\n",
      "location_el granada, california\n",
      "location_el sobrante, california\n",
      "location_emeryville, california\n",
      "location_fairfax, california\n",
      "location_fayetteville, west virginia\n",
      "location_forest knolls, california\n",
      "location_fort lauderdale, florida\n",
      "location_foster city, california\n",
      "location_freedom, california\n",
      "location_fremont, california\n",
      "location_glencove, california\n",
      "location_grand rapids, michigan\n",
      "location_granite bay, california\n",
      "location_green brae, california\n",
      "location_guadalajara, mexico\n",
      "location_hacienda heights, california\n",
      "location_half moon bay, california\n",
      "location_hayward, california\n",
      "location_hercules, california\n",
      "location_hilarita, california\n",
      "location_hillsborough, california\n",
      "location_honolulu, hawaii\n",
      "location_irvine, california\n",
      "location_isla vista, california\n",
      "location_islip terrace, new york\n",
      "location_jackson, mississippi\n",
      "location_kansas city, missouri\n",
      "location_kassel, germany\n",
      "location_kensington, california\n",
      "location_kentfield, california\n",
      "location_kula, hawaii\n",
      "location_lafayette, california\n",
      "location_lagunitas, california\n",
      "location_lake orion, michigan\n",
      "location_larkspur, california\n",
      "location_las vegas, nevada\n",
      "location_leander, texas\n",
      "location_livingston, california\n",
      "location_london, united kingdom\n",
      "location_long beach, california\n",
      "location_long beach, new york\n",
      "location_longwood, florida\n",
      "location_los angeles, california\n",
      "location_los gatos, california\n",
      "location_madrid, spain\n",
      "location_magalia, california\n",
      "location_marin city, california\n",
      "location_martinez, california\n",
      "location_menlo park, california\n",
      "location_miami, florida\n",
      "location_mill valley, california\n",
      "location_millbrae, california\n",
      "location_milpitas, california\n",
      "location_milwaukee, wisconsin\n",
      "location_minneapolis, minnesota\n",
      "location_modesto, california\n",
      "location_montara, california\n",
      "location_moraga, california\n",
      "location_moss beach, california\n",
      "location_mountain view, california\n",
      "location_muir beach, california\n",
      "location_murfreesboro, tennessee\n",
      "location_napa, california\n",
      "location_nevada city, california\n",
      "location_new orleans, louisiana\n",
      "location_new york, new york\n",
      "location_nha trang, vietnam\n",
      "location_nicasio, california\n",
      "location_north hollywood, california\n",
      "location_novato, california\n",
      "location_oakland, california\n",
      "location_oakley, california\n",
      "location_oceanview, california\n",
      "location_olema, california\n",
      "location_orange, california\n",
      "location_orinda, california\n",
      "location_ozone park, new york\n",
      "location_pacheco, california\n",
      "location_pacifica, california\n",
      "location_palo alto, california\n",
      "location_pasadena, california\n",
      "location_peoria, illinois\n",
      "location_petaluma, california\n",
      "location_philadelphia, pennsylvania\n",
      "location_phoenix, arizona\n",
      "location_piedmont, california\n",
      "location_pinole, california\n",
      "location_pleasant hill, california\n",
      "location_point richmond, california\n",
      "location_port costa, california\n",
      "location_portland, oregon\n",
      "location_providence, rhode island\n",
      "location_redwood city, california\n",
      "location_redwood shores, california\n",
      "location_richmond, california\n",
      "location_riverside, california\n",
      "location_rochester, michigan\n",
      "location_rodeo, california\n",
      "location_rohnert park, california\n",
      "location_ross, california\n",
      "location_sacramento, california\n",
      "location_salt lake city, utah\n",
      "location_san anselmo, california\n",
      "location_san antonio, texas\n",
      "location_san bruno, california\n",
      "location_san carlos, california\n",
      "location_san diego, california\n",
      "location_san francisco, california\n",
      "location_san geronimo, california\n",
      "location_san jose, california\n",
      "location_san leandro, california\n",
      "location_san lorenzo, california\n",
      "location_san luis obispo, california\n",
      "location_san mateo, california\n",
      "location_san pablo, california\n",
      "location_san quentin, california\n",
      "location_san rafael, california\n",
      "location_santa ana, california\n",
      "location_santa clara, california\n",
      "location_santa cruz, california\n",
      "location_santa monica, california\n",
      "location_santa rosa, california\n",
      "location_sausalito, california\n",
      "location_seaside, california\n",
      "location_seattle, washington\n",
      "location_south lake tahoe, california\n",
      "location_south orange, new jersey\n",
      "location_south san francisco, california\n",
      "location_south wellfleet, massachusetts\n",
      "location_stanford, california\n",
      "location_stinson beach, california\n",
      "location_stockton, california\n",
      "location_stratford, connecticut\n",
      "location_studio city, california\n",
      "location_sunnyvale, california\n",
      "location_taunton, massachusetts\n",
      "location_tiburon, california\n",
      "location_tucson, arizona\n",
      "location_union city, california\n",
      "location_utica, michigan\n",
      "location_vacaville, california\n",
      "location_vallejo, california\n",
      "location_vancouver, british columbia, canada\n",
      "location_walnut creek, california\n",
      "location_washington, district of columbia\n",
      "location_waterford, california\n",
      "location_west oakland, california\n",
      "location_westlake, california\n",
      "location_woodacre, california\n",
      "location_woodbridge, virginia\n",
      "location_woodside, california\n",
      "location_nan\n",
      "orientation_bisexual\n",
      "orientation_gay\n",
      "orientation_straight\n",
      "orientation_nan\n",
      "pets_dislikes cats\n",
      "pets_dislikes dogs\n",
      "pets_dislikes dogs and dislikes cats\n",
      "pets_dislikes dogs and has cats\n",
      "pets_dislikes dogs and likes cats\n",
      "pets_has cats\n",
      "pets_has dogs\n",
      "pets_has dogs and dislikes cats\n",
      "pets_has dogs and has cats\n",
      "pets_has dogs and likes cats\n",
      "pets_likes cats\n",
      "pets_likes dogs\n",
      "pets_likes dogs and dislikes cats\n",
      "pets_likes dogs and has cats\n",
      "pets_likes dogs and likes cats\n",
      "pets_nan\n",
      "religion_agnosticism\n",
      "religion_agnosticism and laughing about it\n",
      "religion_agnosticism and somewhat serious about it\n",
      "religion_agnosticism and very serious about it\n",
      "religion_agnosticism but not too serious about it\n",
      "religion_atheism\n",
      "religion_atheism and laughing about it\n",
      "religion_atheism and somewhat serious about it\n",
      "religion_atheism and very serious about it\n",
      "religion_atheism but not too serious about it\n",
      "religion_buddhism\n",
      "religion_buddhism and laughing about it\n",
      "religion_buddhism and somewhat serious about it\n",
      "religion_buddhism and very serious about it\n",
      "religion_buddhism but not too serious about it\n",
      "religion_catholicism\n",
      "religion_catholicism and laughing about it\n",
      "religion_catholicism and somewhat serious about it\n",
      "religion_catholicism and very serious about it\n",
      "religion_catholicism but not too serious about it\n",
      "religion_christianity\n",
      "religion_christianity and laughing about it\n",
      "religion_christianity and somewhat serious about it\n",
      "religion_christianity and very serious about it\n",
      "religion_christianity but not too serious about it\n",
      "religion_hinduism\n",
      "religion_hinduism and laughing about it\n",
      "religion_hinduism and somewhat serious about it\n",
      "religion_hinduism and very serious about it\n",
      "religion_hinduism but not too serious about it\n",
      "religion_islam\n",
      "religion_islam and laughing about it\n",
      "religion_islam and somewhat serious about it\n",
      "religion_islam and very serious about it\n",
      "religion_islam but not too serious about it\n",
      "religion_judaism\n",
      "religion_judaism and laughing about it\n",
      "religion_judaism and somewhat serious about it\n",
      "religion_judaism and very serious about it\n",
      "religion_judaism but not too serious about it\n",
      "religion_other\n",
      "religion_other and laughing about it\n",
      "religion_other and somewhat serious about it\n",
      "religion_other and very serious about it\n",
      "religion_other but not too serious about it\n",
      "religion_nan\n",
      "sex_f\n",
      "sex_m\n",
      "sex_nan\n",
      "sign_aquarius\n",
      "sign_aquarius and it matters a lot\n",
      "sign_aquarius and it&rsquo;s fun to think about\n",
      "sign_aquarius but it doesn&rsquo;t matter\n",
      "sign_aries\n",
      "sign_aries and it matters a lot\n",
      "sign_aries and it&rsquo;s fun to think about\n",
      "sign_aries but it doesn&rsquo;t matter\n",
      "sign_cancer\n",
      "sign_cancer and it matters a lot\n",
      "sign_cancer and it&rsquo;s fun to think about\n",
      "sign_cancer but it doesn&rsquo;t matter\n",
      "sign_capricorn\n",
      "sign_capricorn and it matters a lot\n",
      "sign_capricorn and it&rsquo;s fun to think about\n",
      "sign_capricorn but it doesn&rsquo;t matter\n",
      "sign_gemini\n",
      "sign_gemini and it matters a lot\n",
      "sign_gemini and it&rsquo;s fun to think about\n",
      "sign_gemini but it doesn&rsquo;t matter\n",
      "sign_leo\n",
      "sign_leo and it matters a lot\n",
      "sign_leo and it&rsquo;s fun to think about\n",
      "sign_leo but it doesn&rsquo;t matter\n",
      "sign_libra\n",
      "sign_libra and it matters a lot\n",
      "sign_libra and it&rsquo;s fun to think about\n",
      "sign_libra but it doesn&rsquo;t matter\n",
      "sign_pisces\n",
      "sign_pisces and it matters a lot\n",
      "sign_pisces and it&rsquo;s fun to think about\n",
      "sign_pisces but it doesn&rsquo;t matter\n",
      "sign_sagittarius\n",
      "sign_sagittarius and it matters a lot\n",
      "sign_sagittarius and it&rsquo;s fun to think about\n",
      "sign_sagittarius but it doesn&rsquo;t matter\n",
      "sign_scorpio\n",
      "sign_scorpio and it matters a lot\n",
      "sign_scorpio and it&rsquo;s fun to think about\n",
      "sign_scorpio but it doesn&rsquo;t matter\n",
      "sign_taurus\n",
      "sign_taurus and it matters a lot\n",
      "sign_taurus and it&rsquo;s fun to think about\n",
      "sign_taurus but it doesn&rsquo;t matter\n",
      "sign_virgo\n",
      "sign_virgo and it matters a lot\n",
      "sign_virgo and it&rsquo;s fun to think about\n",
      "sign_virgo but it doesn&rsquo;t matter\n",
      "sign_nan\n",
      "smokes_no\n",
      "smokes_sometimes\n",
      "smokes_trying to quit\n",
      "smokes_when drinking\n",
      "smokes_yes\n",
      "smokes_nan\n",
      "status_available\n",
      "status_married\n",
      "status_seeing someone\n",
      "status_single\n",
      "status_unknown\n",
      "status_nan\n"
     ]
    }
   ],
   "source": [
    "for x in df.columns:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
