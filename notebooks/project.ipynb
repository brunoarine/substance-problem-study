{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/profiles.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's drop all the columns we won't use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['last_online'], axis=1, inplace=True)\n",
    "df.drop([f\"essay{n}\" for n in np.arange(0,10)], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"diet\" variable has 6 possible cuisines (anything, vegetarian, vegan, kosher, halal, and other) and 2 changers (mostly/strictly), which might create unnecessary dummy variables that won't add value to the model. So let's boil it down to diet type without the nuance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          anything\n",
       "1             other\n",
       "2          anything\n",
       "3        vegetarian\n",
       "4               NaN\n",
       "            ...    \n",
       "59941           NaN\n",
       "59942      anything\n",
       "59943      anything\n",
       "59944      anything\n",
       "59945           NaN\n",
       "Name: diet, Length: 59946, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diet'].replace([\"mostly \", \"strictly \"], \"\", regex=True, inplace=True)\n",
    "df['diet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same goes for the `language` variable. There are 3 modifiers for a multitude of languages. The permutation between all possible values will generate thousands of unnecessary columns. Let's just keep the languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                            english\n",
       "1                           english, spanish, french\n",
       "2                               english, french, c++\n",
       "3                                    english, german\n",
       "4                                            english\n",
       "                            ...                     \n",
       "59941                                        english\n",
       "59942                                        english\n",
       "59943                                        english\n",
       "59944    english, spanish, chinese, korean, japanese\n",
       "59945                                        english\n",
       "Name: speaks, Length: 59946, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['speaks'].replace([\" \\(fluently\\)\", \" \\(okay\\)\", \" \\(poorly\\)\"], \"\", regex=True, inplace=True)\n",
    "df[\"speaks\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But filtering out the language modifiers isn't enough. There's only one column for all the user's spoken languages, whose combination might generate a dozen thousands dummy variables. Therefore, each `speaks` value should be parsed and gain a dummy variable of its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([      'english',             nan,     'afrikaans',        'french',\\n          'portuguese',            None,       'spanish',        'german',\\n             'chinese', 'sign language',           'c++',       'tagalog',\\n               'other',       'russian',         'dutch',    'indonesian',\\n             'swedish',     'belarusan',      'japanese',         'farsi',\\n             'italian',         'hindi',        'polish',        'korean',\\n               'czech',      'croatian',    'vietnamese',     'esperanto',\\n               'latin',         'greek',     'norwegian',        'hebrew',\\n              'arabic',       'tibetan',      'georgian',          'thai',\\n             'swahili',         'khmer',       'turkish',         'tamil',\\n                'lisp',       'serbian',      'sanskrit',       'bengali',\\n             'catalan',     'hungarian',         'irish',          'urdu',\\n            'romanian',       'finnish',     'bulgarian', 'ancient greek',\\n             'yiddish',      'hawaiian',    'lithuanian',       'cebuano',\\n             'persian',         'maori',        'danish',      'gujarati',\\n            'albanian',       'frisian',        'ilongo',     'icelandic',\\n           'slovenian',       'latvian',       'occitan',         'malay',\\n           'mongolian',       'rotuman',        'slovak',     'ukrainian',\\n            'armenian',      'estonian',       'chechen',         'welsh',\\n              'basque',        'breton',     'sardinian'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-22de12deea1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlang_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'speaks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\", \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlang_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'K'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mspeaks_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"speaks\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlang_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf_no_speaks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"speaks\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_languages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_no_speaks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeaks_table\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36mget_dummies\u001b[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m    845\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input must be a list-like for parameter `columns`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m             \u001b[0mdata_to_encode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;31m# validate prefixes and separator to avoid silently dropping cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3028\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3029\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3030\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3032\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m             \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index([      'english',             nan,     'afrikaans',        'french',\\n          'portuguese',            None,       'spanish',        'german',\\n             'chinese', 'sign language',           'c++',       'tagalog',\\n               'other',       'russian',         'dutch',    'indonesian',\\n             'swedish',     'belarusan',      'japanese',         'farsi',\\n             'italian',         'hindi',        'polish',        'korean',\\n               'czech',      'croatian',    'vietnamese',     'esperanto',\\n               'latin',         'greek',     'norwegian',        'hebrew',\\n              'arabic',       'tibetan',      'georgian',          'thai',\\n             'swahili',         'khmer',       'turkish',         'tamil',\\n                'lisp',       'serbian',      'sanskrit',       'bengali',\\n             'catalan',     'hungarian',         'irish',          'urdu',\\n            'romanian',       'finnish',     'bulgarian', 'ancient greek',\\n             'yiddish',      'hawaiian',    'lithuanian',       'cebuano',\\n             'persian',         'maori',        'danish',      'gujarati',\\n            'albanian',       'frisian',        'ilongo',     'icelandic',\\n           'slovenian',       'latvian',       'occitan',         'malay',\\n           'mongolian',       'rotuman',        'slovak',     'ukrainian',\\n            'armenian',      'estonian',       'chechen',         'welsh',\\n              'basque',        'breton',     'sardinian'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "lang_table = df['speaks'].str.split(pat=\", \", expand=True)\n",
    "lang_columns = pd.unique(lang_table.values.ravel('K'))\n",
    "speaks_table = pd.get_dummies(lang_table, prefix=\"speaks\", columns=lang_columns)\n",
    "df_no_speaks = df.drop([\"speaks\"], axis=1)\n",
    "df_languages = pd.concat([df_no_speaks, speaks_table], axis=1)\n",
    "lang_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_speak_col(df):\n",
    "    lang_spoken = df['speaks'].str.split(pat=\", \", expand=True)\n",
    "    lang_columns = pd.unique(lang_spoken.values.ravel('K'))\n",
    "    table_shape = (df.shape[0], len(lang_columns))\n",
    "    lang_table = pd.DataFrame(np.zeros(table_shape, dtype=\"int\"),\n",
    "                              columns=[f\"speaks_{lang}\" for lang in lang_columns])\n",
    "    for index,row in lang_spoken.iterrows():\n",
    "        for item in row:\n",
    "            lang_table.at[index, f\"speaks_{item}\"] = 1\n",
    "   \n",
    "    lang_table.drop([\"speaks_None\"], axis=1, inplace=True)\n",
    "    df_no_speak = df.drop(\"speaks\", axis=1)\n",
    "    return pd.concat([df_no_speak, lang_table], axis=1)\n",
    "\n",
    "df_spoken_langs = convert_speak_col(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy(df):\n",
    "    \"\"\"\n",
    "    Creates dummy variables for all the categorial variables in a DataFrame and concatenates it\n",
    "    with the original numerical columns.\n",
    "    Input: pandas DataFrame\n",
    "    Output: pandas DataFrame\n",
    "    \"\"\"\n",
    "    cat_cols = df.select_dtypes(include=\"object\").columns\n",
    "    num_cols = df.select_dtypes(exclude=\"object\").columns\n",
    "    dummy_df = pd.get_dummies(df[cat_cols],\n",
    "                              prefix=cat_cols,\n",
    "                              prefix_sep=\"_\",\n",
    "                              dummy_na=True,\n",
    "                              columns=cat_cols)\n",
    "                              \n",
    "    df_new = pd.concat([df[num_cols], dummy_df], axis=1)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>income</th>\n",
       "      <th>speaks_english</th>\n",
       "      <th>speaks_nan</th>\n",
       "      <th>speaks_afrikaans</th>\n",
       "      <th>speaks_french</th>\n",
       "      <th>speaks_portuguese</th>\n",
       "      <th>speaks_spanish</th>\n",
       "      <th>speaks_german</th>\n",
       "      <th>...</th>\n",
       "      <th>smokes_trying to quit</th>\n",
       "      <th>smokes_when drinking</th>\n",
       "      <th>smokes_yes</th>\n",
       "      <th>smokes_nan</th>\n",
       "      <th>status_available</th>\n",
       "      <th>status_married</th>\n",
       "      <th>status_seeing someone</th>\n",
       "      <th>status_single</th>\n",
       "      <th>status_unknown</th>\n",
       "      <th>status_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>68.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>71.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 731 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  height  income  speaks_english  speaks_nan  speaks_afrikaans  \\\n",
       "0   22    75.0      -1               1           0                 0   \n",
       "1   35    70.0   80000               1           0                 0   \n",
       "2   38    68.0      -1               1           0                 0   \n",
       "3   23    71.0   20000               1           0                 0   \n",
       "4   29    66.0      -1               1           0                 0   \n",
       "\n",
       "   speaks_french  speaks_portuguese  speaks_spanish  speaks_german  ...  \\\n",
       "0              0                  0               0              0  ...   \n",
       "1              1                  0               1              0  ...   \n",
       "2              1                  0               0              0  ...   \n",
       "3              0                  0               0              1  ...   \n",
       "4              0                  0               0              0  ...   \n",
       "\n",
       "   smokes_trying to quit  smokes_when drinking  smokes_yes  smokes_nan  \\\n",
       "0                      0                     0           0           0   \n",
       "1                      0                     0           0           0   \n",
       "2                      0                     0           0           0   \n",
       "3                      0                     0           0           0   \n",
       "4                      0                     0           0           0   \n",
       "\n",
       "   status_available  status_married  status_seeing someone  status_single  \\\n",
       "0                 0               0                      0              1   \n",
       "1                 0               0                      0              1   \n",
       "2                 1               0                      0              0   \n",
       "3                 0               0                      0              1   \n",
       "4                 0               0                      0              1   \n",
       "\n",
       "   status_unknown  status_nan  \n",
       "0               0           0  \n",
       "1               0           0  \n",
       "2               0           0  \n",
       "3               0           0  \n",
       "4               0           0  \n",
       "\n",
       "[5 rows x 731 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummies = create_dummy(df_spoken_langs)\n",
    "df_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['english', nan, 'afrikaans', 'french', 'portuguese', None,\n",
       "       'spanish', 'german', 'chinese', 'sign language', 'c++', 'tagalog',\n",
       "       'other', 'russian', 'dutch', 'indonesian', 'swedish', 'belarusan',\n",
       "       'japanese', 'farsi', 'italian', 'hindi', 'polish', 'korean',\n",
       "       'czech', 'croatian', 'vietnamese', 'esperanto', 'latin', 'greek',\n",
       "       'norwegian', 'hebrew', 'arabic', 'tibetan', 'georgian', 'thai',\n",
       "       'swahili', 'khmer', 'turkish', 'tamil', 'lisp', 'serbian',\n",
       "       'sanskrit', 'bengali', 'catalan', 'hungarian', 'irish', 'urdu',\n",
       "       'romanian', 'finnish', 'bulgarian', 'ancient greek', 'yiddish',\n",
       "       'hawaiian', 'lithuanian', 'cebuano', 'persian', 'maori', 'danish',\n",
       "       'gujarati', 'albanian', 'frisian', 'ilongo', 'icelandic',\n",
       "       'slovenian', 'latvian', 'occitan', 'malay', 'mongolian', 'rotuman',\n",
       "       'slovak', 'ukrainian', 'armenian', 'estonian', 'chechen', 'welsh',\n",
       "       'basque', 'breton', 'sardinian'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see https://stackoverflow.com/questions/26977076/pandas-unique-values-multiple-columns \n",
    "pd.unique(lang_table.values.ravel('K'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
