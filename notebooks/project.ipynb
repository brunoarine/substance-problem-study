{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/profiles.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove unneeded variables\n",
    "\n",
    "First, let's drop all the columns we won't use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['last_online'], axis=1, inplace=True)\n",
    "df.drop([f\"essay{n}\" for n in np.arange(0,10)], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactor \"diet\" variable\n",
    "\n",
    "The \"diet\" variable has 6 possible cuisines (anything, vegetarian, vegan, kosher, halal, and other) and 2 changers (mostly/strictly), which might create unnecessary dummy variables that won't add value to the model. So let's boil it down to diet type without the nuance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          anything\n",
       "1             other\n",
       "2          anything\n",
       "3        vegetarian\n",
       "4               NaN\n",
       "            ...    \n",
       "59941           NaN\n",
       "59942      anything\n",
       "59943      anything\n",
       "59944      anything\n",
       "59945           NaN\n",
       "Name: diet, Length: 59946, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diet'].replace([\"mostly \", \"strictly \"], \"\", regex=True, inplace=True)\n",
    "df['diet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse spoken languages\n",
    "\n",
    "The same goes for the `language` variable. There are 3 modifiers for a multitude of languages. The permutation between all possible values will generate thousands of unnecessary columns. Let's just keep the languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                            english\n",
       "1                           english, spanish, french\n",
       "2                               english, french, c++\n",
       "3                                    english, german\n",
       "4                                            english\n",
       "                            ...                     \n",
       "59941                                        english\n",
       "59942                                        english\n",
       "59943                                        english\n",
       "59944    english, spanish, chinese, korean, japanese\n",
       "59945                                        english\n",
       "Name: speaks, Length: 59946, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['speaks'].replace([\" \\(fluently\\)\", \" \\(okay\\)\", \" \\(poorly\\)\"], \"\", regex=True, inplace=True)\n",
    "df[\"speaks\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But filtering out the language modifiers isn't enough. There's only one column for all the user's spoken languages, whose combination might generate a dozen thousands dummy variables. Therefore, each `speaks` value should be parsed and gain a dummy variable of its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_to_dummies(df, column):\n",
    "    \"\"\"\n",
    "    Transforms a column with comma-separated values into new 0-or-1 columns.\n",
    "    \"\"\"\n",
    "    expanded_values = df[column].str.split(pat=\", \", expand=True)\n",
    "    # see https://stackoverflow.com/questions/26977076/pandas-unique-values-multiple-columns \n",
    "    unique_labels = pd.unique(expanded_values.values.ravel('K'))\n",
    "    table_shape = (df.shape[0], len(unique_labels))\n",
    "    dummy_table = pd.DataFrame(np.zeros(table_shape, dtype=\"int\"),\n",
    "                              columns=[f\"{column}_{label}\" for label in unique_labels])\n",
    "    for index,row in expanded_values.iterrows():\n",
    "        for item in row:\n",
    "            dummy_table.at[index, f\"{column}_{item}\"] = 1\n",
    "   \n",
    "    dummy_table.drop([f\"{column}_None\"], axis=1, inplace=True)\n",
    "    df_drop_column = df.drop(column, axis=1)\n",
    "    return pd.concat([df_drop_column, dummy_table], axis=1)\n",
    "\n",
    "df = parse_to_dummies(df, column=\"speaks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert \"drink\" values into a numerical scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[print(x) for x in df.columns]\n",
    "df['drinks'].replace({\"not at all\": 0,\n",
    "                     \"rarely\": 1,\n",
    "                     \"socially\": 2,\n",
    "                     \"often\": 3,\n",
    "                     \"very often\": 4,\n",
    "                     \"desperately\": 5}, inline=True)\n",
    "df['drinks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dummy variables from categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy(df):\n",
    "    \"\"\"\n",
    "    Creates dummy variables for all the categorial variables in a DataFrame and concatenates it\n",
    "    with the original numerical columns.\n",
    "    Input: pandas DataFrame\n",
    "    Output: pandas DataFrame\n",
    "    \"\"\"\n",
    "    cat_cols = df.select_dtypes(include=\"object\").columns\n",
    "    num_cols = df.select_dtypes(exclude=\"object\").columns\n",
    "    dummy_df = pd.get_dummies(df[cat_cols],\n",
    "                              prefix=cat_cols,\n",
    "                              prefix_sep=\"_\",\n",
    "                              dummy_na=True,\n",
    "                              columns=cat_cols)\n",
    "                              \n",
    "    df_new = pd.concat([df[num_cols], dummy_df], axis=1)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_dummy(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(x) for x in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
