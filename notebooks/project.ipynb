{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The most common traits of substance abuse\n",
    "\n",
    "In 2017, nearly 20 million American adults (almost 7% of the population) battled a substance abuse problem, costing the US more than $740 billion annually in lost workplace productivity, healthcare expenses, and crime-related costs, according to the [American Addiction Centers](https://americanaddictioncenters.org/rehab-guide/addiction-statistics).\n",
    "\n",
    "Substance abuse has a cure, but many people are too ashamed to reach out for help, which makes the problem even harder to address.\n",
    "\n",
    "What if we could tell whether someone has a potential problem with drugs without asking them explicitly? Maybe we could look out for common traits among people who suffer with substance abuse problems and provide aid in advance. Organizations could target ad campaigns at the right people and right moment and increase their effectiveness.\n",
    "\n",
    "But what would these common traits be?\n",
    "\n",
    "## 1. Problem understanding\n",
    "\n",
    "This study will try to answer the following questions:\n",
    "\n",
    "1. Which age group shows the largest share of people with a possible substance problem? And which gender?\n",
    "\n",
    "2. Which kind of professional is more vulnerable to substance abuse?\n",
    "\n",
    "3. Are people with kids or partners less likely to have a substance problem?\n",
    "\n",
    "4. Are religious people less likely to have a substance problem?\n",
    "\n",
    "5. Does making healthy choices (e.g., not smoking or eating plant-based diets) correlate negatively with substance abuse?\n",
    "\n",
    "And last but not least, how accurately can we predict substance abuse with just this bunch of information?\n",
    "\n",
    "## 2. Data understanding\n",
    "\n",
    "To tackle the previous questions, I'm going to use the [OkCupid Profile Dataset](https://github.com/rudeboybert/JSE_OkCupid), a file containing answers from 60k users covering a number of topics; from marital status, job, and kids, to alcohol and drugs consumption.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/profiles.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the useful variables\n",
    "\n",
    "These are the variables that will help me address the proposed questions:\n",
    "- diet\n",
    "- drinks\n",
    "- drugs\n",
    "- job\n",
    "- offspring\n",
    "- pets\n",
    "- religion\n",
    "- sex\n",
    "- smokes\n",
    "- status\n",
    "\n",
    "Let's ditch all the rest:\n",
    "\n",
    "- body_type\n",
    "- education\n",
    "- ethnicity\n",
    "- height\n",
    "- income\n",
    "- last_online\n",
    "- location\n",
    "- orientation\n",
    "- sign\n",
    "- speaks\n",
    "- essay from 0 to 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"body_type\", \"education\", \"ethnicity\", \"height\", \"income\", \"last_online\", \"location\", \"orientation\",\n",
    "        \"sign\", \"speaks\", \"essay0\", \"essay1\", \"essay2\", \"essay3\", \"essay4\", \"essay5\", \"essay6\",\n",
    "        \"essay7\", \"essay8\", \"essay9\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable descriptions\n",
    "\n",
    "The following details are also provided in the dataset codebook.\n",
    "\n",
    "Missing data is blank. Some variables have two factors, which are denoted in this codebook by a semicolon (e.g. \"graduated from; two-year college) though they are found without punctuation in the dataset. Details for specific variables are found in parenthesis.\n",
    "\n",
    "**diet** - mostly/strictly; anything, vegetarian, vegan, kosher, halal, other\n",
    "\n",
    "**drinks** - very often, often, socially, rarely, desperately, not at all\n",
    "\n",
    "**drugs** - never, sometimes, often\n",
    "\n",
    "**job** - student, art/music/writing, banking/finance, administration, technology, construction, education, entertainment/media, management, hospitality, law, medicine, military, politics/government, sales/marketing, science/engineering, transportation, unemployed, other, rather not say, retire\n",
    "\n",
    "**offspring** - has a kid, has kids, doesnt have a kid, doesn't want kids; ,and/,but might want them, wants them, doesnt want any, doesnt want more\n",
    "\n",
    "**orientation** - straight, gay, bisexual\n",
    "\n",
    "**pets** - has dogs, likes dogs, dislikes dogs; and has cats, likes cats, dislikes cats\n",
    "\n",
    "**religion** - agnosticism, atheism, Christianity, Judaism, Catholicism, Islam, Hinduism, Buddhism, Other; and very serious about it, and somewhat serious about it, but not too serious about it, and laughing about it\n",
    "\n",
    "**sex** - m, f\n",
    "\n",
    "**smokes** - yes, sometimes, when drinking, trying to quit, no\n",
    "\n",
    "**status** - single, seeing someone, married, in an open relationship\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the actual data type is the same as their description in the codebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The database has 60k rows, but there's a huge number of missing values, especially in the `offspring` column. People have their own personal reasons not to answer a survey, like taboo or fear of exposition. That makes it a MNAR (Missing Not At Random) scenario, which is quite difficult to handle. I'm not a huge fan of imputing the missing values with estimates in this case (even with multivariate methods like KNN) because doing so will likely create some sort of bias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That will would leave us only ~15% of original data, which is still beter than coming up with estimates (and risking affect the $\\chi^2$ tests later).\n",
    "\n",
    "Nonetheless, there's no need to drop all the missing rows right now. While analyzing the variables individually, I can drop *just the missing values that belong to the variables being analyzed.* That way, I still got a bit of statistical power for chi-squared tests. After the individual analyzes are done, then all missing values will be dropped before training the machine learning model.\n",
    "\n",
    "In sum: the NaNs-containing rows are going to be dropped shortly before I evaluate the final model. Until then, only the missing values in the target variable will be dropped, along with the missing values in each of the column being analyzed along Section 4 - Evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining and creating the target variable\n",
    "\n",
    "First, we need to clearly define what substance abuse is. According to [Wikipedia](https://en.wikipedia.org/wiki/Substance_abuse):\n",
    "\n",
    "> Substance abuse, also known as drug abuse, is use of a drug in amounts or by methods which are harmful to the individual or others. (...) Drugs most often associated with this term include: alcohol, amphetamines, barbiturates, benzodiazepines, cannabis, cocaine, hallucinogens, methaqualone, and opioids.\n",
    "\n",
    "The OkCupid dataset isn't precise in terms of which drugs its users consume, but it gives us a few clues about quantity: \n",
    "\n",
    "- The `drinks` variable has 6 possible values: very often, often, socially, rarely, desperately, not at all\n",
    "- The `drugs` variable has 3 possible values: never, sometimes, often\n",
    "\n",
    "I'm going to assume that users who drink \"very often\", or use drugs \"often\" are likely candidates for the group of users with a substance problem. I dismissed \"desperately\" entries because this sounds more like an answer to signal you're cool.\n",
    "\n",
    "I'm going to name it as `abuse`, and convert the possible values of `drinks` and `drugs` the variables `alcohol_problem`, `drugs_problem`, and `both_problems`, which will either be 0 or 1. But before that, I'm going to drop the missing values in both columns because I want the target column to be devoid of NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dropna(axis=0, subset=[\"drinks\", \"drugs\"], inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, dropping the null values for the target variable left us with 75% of the original data, which is acceptable for me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates alcohol_problem column with values:\n",
    "# 1 if drinks = \"very often\", 0 if anything else.\n",
    "# Not considering the \"desperately\" entries improved the model accuracy at the end of this notebook,\n",
    "# which kinda proves my point.\n",
    "df[\"alcohol_problem\"] = df['drinks'].str.contains(\"very often\")\n",
    "\n",
    "# Creates drugs_problem column with values:\n",
    "# 1 if drinks = \"often\"\n",
    "# 0 if anything else\n",
    "df[\"drugs_problem\"] = df['drugs'].str.contains(\"often\")\n",
    "\n",
    "# Users have an abuse problem (abuse = 1) if they have either an alcohol or drug abuse problem;\n",
    "df['abuse'] = (df['alcohol_problem'] | df['drugs_problem'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A user may have a drug abuse problem, an alcohol abuse problem, or both. I want to discriminate each so that I can make a stacked bar plot in the analysis section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['both_problems'] = (df[\"drugs_problem\"] & df[\"alcohol_problem\"])\n",
    "df['alcohol_problem_only'] = (df['alcohol_problem'] & ~df['drugs_problem'])\n",
    "df['drugs_problem_only'] = (~df['alcohol_problem'] & df['drugs_problem'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several populational traits have a potentially strong correlation with age (e.g. having kids). Therefore I want to create a variable called `age_group` so that I can assess whether my hypotheses hold for all ages when analyzing the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_group_labels = [\"18 to 25\", \"25 to 29\", \"30 to 39\", \"40+\"]\n",
    "df[\"age_group\"] = pd.cut(df['age'], bins=[18,25,30,40,100], labels=age_group_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision upon age intervals was such that each bin contained roughly the same number of users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"age_group\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a female variable, so that gender can be either 0 or 1 to maintain the same format as\n",
    "# the other variables\n",
    "df[\"female\"] = df[\"sex\"].replace({\"m\": 0, \"f\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an \"unemployed\" variable to reduce the number of features for the machine learning model\n",
    "df[\"unemployed\"] = df[\"job\"].copy()\n",
    "df.loc[df[\"job\"].notna(), \"unemployed\"] = (df[\"job\"] == \"unemployed\") | (df[\"job\"] == \"rather not say\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `okcupid_codebook.txt` file tells that all missing values are presented as an empty string in the CSV file. That's not the case with `status`. (I thought it was strange that such a column didn't have one single missing value in a dataset with 60k answers!) The missing values here are stated as \"unknown\". I'll replace those with NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['status'].replace(\"unknown\", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the `okcupid_codebook.txt` file, the possible values of `status` are single, seeing someone, married, and in an open relationship. I'll replace the value \"available\" with the latter since it's more explainative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"status\"] = df[\"status\"].replace({\"available\": \"in an open relationship\"})\n",
    "\n",
    "# Create a \"married\" variable to reduce the number of features for the machine learning model\n",
    "df[\"married\"] = df[\"status\"].str.contains(\"married\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offspring "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoever answered \"doesn't have kids\" (and might or might not want them), or simply \"wants kids\" will have the `offspring` variable set to zero, while everything else will be replaced with ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['offspring'].replace(['doesn&rsquo;t have kids',\n",
    "                         'doesn&rsquo;t have kids, and doesn&rsquo;t want any',\n",
    "                         'doesn&rsquo;t have kids, but might want them',\n",
    "                         'doesn&rsquo;t have kids, but wants them',\n",
    "                         'might want kids',\n",
    "                         'doesn&rsquo;t want kids',\n",
    "                         'wants kids'], 0, inplace=True)\n",
    "\n",
    "df['offspring'].replace(['has a kid',\n",
    "                         'has a kid, and might want more',\n",
    "                         'has a kid, and wants more',\n",
    "                         'has a kid, but doesn&rsquo;t want more',\n",
    "                         'has kids',\n",
    "                         'has kids, and might want more',\n",
    "                         'has kids, and wants more',\n",
    "                         'has kids, but doesn&rsquo;t want more',], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 if person has dogs (or cats), 0 otherwise\n",
    "df['has_dogs'] = df['pets'].str.contains('has dogs')\n",
    "df['has_cats'] = df['pets'].str.contains('has cats')\n",
    "\n",
    "# Make a copy of pets so that all NaNs are at the right position, then\n",
    "# has_pets = 1 when user either has a dog or a cat\n",
    "df['has_pets'] = df['pets']\n",
    "df.loc[df['pets'].notna(), 'has_pets'] = (df['has_dogs'] == 1) | (df['has_cats'] == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Religion \n",
    "\n",
    "The `religion` variable has several possible values plus a few modifiers (\"laughing about it, \"somewhat serious about it\", etc). I thought of creating a new variable out of these modifiers called `religious`, which is going to be 1 if:\n",
    "- `religion` is not atheism or agnosticism (for obvious reasons), and\n",
    "- the `religion` modifier is \"very serious about it\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# religious is 1 if \"very serious\", 0 otherwise\n",
    "df['religious'] = df['religion'].str.contains('very serious')\n",
    "\n",
    "# Conditions: religious remains 1 IF original value is 1 AND not atheist or agnostic\n",
    "cond_religious = df['religious'] == 1\n",
    "cond_notna = df['religious'].notna()\n",
    "cond_not_atheist = ~(df['religion'].str.contains(\"agnosticism\") | df['religion'].str.contains(\"atheism\"))\n",
    "\n",
    "# Replace only rows where values are not nulls. If I don't do that, condition testing will turn\n",
    "# missing values into boolean, because NaN doesn't contain strings \"agnosticism\" or \"atheism\"\n",
    "df.loc[cond_notna, \"religious\"] = cond_religious & cond_not_atheist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Healthy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"smokes\"] = df[\"smokes\"].replace({\"yes\": 1,\n",
    "                                    \"sometimes\": 1,\n",
    "                                    \"when drinking\": 1,\n",
    "                                    \"trying to quit\": 1,\n",
    "                                    \"no\": 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"diet\" variable has 6 possible values (anything, vegetarian, vegan, kosher, halal, and other) and 2 modifiers (mostly/strictly), which might create unnecessary dummy variables that won't add value to the model. So let's boil it down to diet type without the nuance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['diet'].notna(), 'vegetarian'] = df['diet'].str.contains(\"vegetarian\") | df['diet'].str.contains(\"vegan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxiliary functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_test(df, column):\n",
    "    \"\"\"Calculates the p-value of chi-squared tests for a chosen column. The function also\n",
    "    performs the test for all age group in the DataFrame.\n",
    "    \"\"\"\n",
    "    print(\"Chi-squared test\")\n",
    "    print(\"----------------\")\n",
    "    for group in age_group_labels:\n",
    "        df_group = df[df[\"age_group\"] == group]\n",
    "        cont_table = pd.crosstab(df_group[column], df_group['abuse'])\n",
    "        c, p, dof, expected = chi2_contingency(cont_table)\n",
    "        print(f\"Age group: {group}, p = {p:.2g}, chi2 = {c:.2g}, n = {len(df_group[column])}\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vert_barplot(df, bars, label, groupby, title=None, color=None, figsize=(9,5)):\n",
    "    \"\"\"Groups the DataFrame by a specified label (like \"age_group), and plots a pretty bar chart\n",
    "    with custom parameters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    df : DataFrame\n",
    "    bars : list of tuples\n",
    "        Contains pairs of columns labels and values to be plotted.\n",
    "        Example: [(\"offspring\", 0), (\"offspring, 1\")]\n",
    "    groupby : str\n",
    "        Column label by which the DataFrame is going to be grouped\n",
    "    title : str\n",
    "        x-axis label\n",
    "    color : list\n",
    "        List of colors to be passed to the plotting method.\n",
    "    figsize : tuple\n",
    "        Figure size\n",
    "    \"\"\"\n",
    "    \n",
    "    df_dropna = df.dropna(axis=0, subset=[x[0] for x in bars])\n",
    "    table_mean = []\n",
    "    for i in range(len(bars)):\n",
    "        col_name = bars[i][0]\n",
    "        col_value = bars[i][1]\n",
    "        table_mean.append(df_dropna[df_dropna[col_name] == col_value]\n",
    "                                .groupby(groupby, dropna=True)[\"abuse\"]\n",
    "                                .mean()\n",
    "                                .to_frame())\n",
    "    table_p = pd.concat(table_mean, axis=1)\n",
    "    \n",
    "    table_percent = table_p * 100  # percentages should be multiplied by 100\n",
    "    \n",
    "    \n",
    "    table_percent.columns = label\n",
    "    table_percent.plot.bar(figsize=figsize,\n",
    "                           color=color,\n",
    "                           rot=0,\n",
    "                           capsize=0)\n",
    "    plt.ylabel(\"% of users with substance problem\")\n",
    "    plt.xlabel(title)\n",
    "    sns.despine()\n",
    "    plt.tight_layout()  # prevents excess white space in the borders\n",
    "    plt.savefig(f\"../results/{bars[0][0]}.png\")\n",
    "    plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def horz_barplot(df, column, figsize=(10,10), barwidth=0.75, legend_height=1.05):\n",
    "    column_stacked = df.groupby(column).mean()[['alcohol_problem_only',\n",
    "                                                   'drugs_problem_only',\n",
    "                                                   'both_problems',\n",
    "                                                   'abuse']].sort_values('abuse')*100\n",
    "    sns.set_palette(\"rocket_r\")\n",
    "    column_stacked.drop('abuse', axis=1, inplace=True)\n",
    "    column_stacked.plot(kind='barh', stacked=True, figsize=figsize, width=barwidth, linewidth=0)\n",
    "    plt.ylabel(\"\")\n",
    "    plt.xlabel(\"% of users with possible substance problems\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.legend(loc='upper center', \n",
    "               bbox_to_anchor=(0.5, legend_height),\n",
    "              ncol=3, fancybox=True, shadow=True)\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"../results/{column}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answering the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"abuse\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Less than 3% of the users in this dataset have a probable substance problem. This is a specially imbalanced dataset, so any attempts to predict an outcome will likely be impacted. Techniques to deal with it can be found at the end of the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #1 - Which age group shows the largest percentage of people with a possible substance addiction problem? And does substance abuse disproportionately affect any gender?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_colors = sns.color_palette(\"colorblind\").as_hex()\n",
    "color=[gender_colors[0], gender_colors[4]]\n",
    "vert_barplot(df=df,\n",
    "             bars=[(\"female\", 0), (\"female\", 1)],\n",
    "             label=[\"male\", \"female\"],\n",
    "             groupby=\"age_group\",\n",
    "             title=\"age group\",\n",
    "             color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_test(df, \"female\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #2 - Which kind profession is more vulnerable to substance abuse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horz_barplot(df, \"job\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #3 - Are people with kids or partners less likely to have a substance abuse problem?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horz_barplot(df, \"status\", figsize=(10,4), barwidth=0.6, legend_height=1.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Young adults are much less likely to have kids, and that will impact the outcome of the correlation study with substance abuse. It would be more reasonable to observe differences by age groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_offspring = pd.concat([df[\"age_group\"].value_counts(), (1-df.groupby(\"age_group\")[\"offspring\"].mean())*100], axis=1)\n",
    "table_offspring.columns = [\"no. of users\", \"percentage without kids\"]\n",
    "table_offspring.index.rename(\"age group\", inplace=True)\n",
    "table_offspring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_barplot(df=df,\n",
    "             bars=[(\"offspring\", 1), (\"offspring\",0)], \n",
    "             label=[\"with kids\", \"without kids\"],\n",
    "             groupby=\"age_group\",\n",
    "             title=\"age group\",\n",
    "             color=sns.color_palette(\"Paired\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_test(df, \"offspring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_barplot(df=df,\n",
    "             bars=[(\"has_cats\", 1), (\"has_dogs\",0), (\"has_pets\", 0)], \n",
    "             label=[\"cat owners\", \"dog owners\", \"no pets\"],\n",
    "             groupby=\"age_group\",\n",
    "             title=\"age group\",\n",
    "             color=sns.color_palette(\"Paired\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_test(df, \"has_cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_test(df, \"has_dogs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #4 - Are religious people less likely to have a substance abuse problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_barplot(df=df,\n",
    "             bars=[(\"religious\", 1), (\"religious\",0)], \n",
    "             label=[\"takes religion seriously\", \"atheist or cool about it\"],\n",
    "             groupby=\"age_group\",\n",
    "             title=\"age group\",\n",
    "             color=sns.color_palette(\"Paired\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_test(df, \"religious\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #5 - Does making healthy choices (e.g., not smoking or eating plant-based diets) correlate negatively with substance abuse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette(\"colorblind\").as_hex()\n",
    "color = [palette[2], palette[1]]\n",
    "vert_barplot(df=df,\n",
    "             bars=[(\"vegetarian\", 1), (\"vegetarian\",0)], \n",
    "             label=[\"vegetarian\", \"non-vegetarian\"],\n",
    "             groupby=\"age_group\",\n",
    "             title=\"age group\",\n",
    "             color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_test(df, \"vegetarian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_barplot(df=df,\n",
    "             bars=[(\"smokes\", 1), (\"smokes\",0)], \n",
    "             label=[\"smoker\", \"non-smoker\"],\n",
    "             groupby=\"age_group\",\n",
    "             title=\"age group\",\n",
    "             color=sns.color_palette(\"rocket_r\", n_colors=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_test(df, \"smokes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clear up all unused columns and drop all rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_useful = df.drop([\"diet\",\"pets\",\"religion\",\"age_group\", \"alcohol_problem\",\n",
    "                    \"alcohol_problem_only\", \"drugs_problem\", \"drugs_problem_only\",\n",
    "                    \"both_problems\", \"has_pets\", \"job\", \"status\", \"sex\",\"drinks\", \"drugs\"], axis=1)\n",
    "\n",
    "df_useful.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few categorical variables remaining. Let's transform them into dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_useful.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.offspring.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, roc_auc_score, f1_score, recall_score, plot_roc_curve\n",
    "from sklearn.utils import resample\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure convergence, I'm going to create a pipeline and pre-treat the data with StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "y = df_useful[\"abuse\"]\n",
    "X = df_useful.drop([\"abuse\"], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset is severely imbalanced and all attempts to train the model will be impacted unless we deal with it first. I decided to upsample the training set, which means randomly replicating positive cases until we have a 50/50 class split in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate our training data back together\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# separate minority and majority classes\n",
    "not_abuse = df_train[df_train[\"abuse\"] == 0]\n",
    "abuse =  df_train[df_train[\"abuse\"] == 1]\n",
    "\n",
    "# upsample minority\n",
    "abuse_upsampled = resample(abuse,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(not_abuse), # match number in majority class\n",
    "                          random_state=42) # reproducible results\n",
    "\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([not_abuse, abuse_upsampled])\n",
    "\n",
    "y_train = upsampled.abuse\n",
    "X_train = upsampled.drop('abuse', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_table = pd.DataFrame(model.named_steps[\"logisticregression\"].coef_[0], index=X_train.columns, columns=[\"coef\"])\n",
    "coef_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette(\"colorblind\").as_hex()\n",
    "colors = [palette[3] if x < 0 else palette[2] for x in coef_table.values]\n",
    "pos = np.arange(len(coef_table))\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.barh(pos, coef_table[\"coef\"], color=colors)\n",
    "plt.yticks(pos, coef_table.index)\n",
    "plt.axvline(x=0, color='.2')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",model.score(X_test, y_test))\n",
    "print(\"Recall:\",recall_score(y_test, model.predict(X_test)))\n",
    "print(\"ROC AUC:\",roc_auc_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the metrics, the model performed better than I initially expected, even dropping all missing values in the table and working with 15% of the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - (y_test[y_test == 0] == model.predict(X_test[y_test == 0])).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "The ROC curve shows that the model is decent at detecting positive cases, but it still needs a bit of work concerning false positives. At its optimal decision threshold (near to the curve knee), the model has 82.5% probability of correctly detecting positive cases and 22.2% probability of false alarm, which would be slightly annoying in a real world application, to say the least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
