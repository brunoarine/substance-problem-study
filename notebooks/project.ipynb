{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/profiles.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove unneeded variables\n",
    "\n",
    "First, let's drop all the columns we won't use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['last_online', 'location', 'sign'], axis=1, inplace=True)\n",
    "df.drop([f\"essay{n}\" for n in np.arange(0,10)], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactor \"diet\" variable\n",
    "\n",
    "The \"diet\" variable has 6 possible cuisines (anything, vegetarian, vegan, kosher, halal, and other) and 2 changers (mostly/strictly), which might create unnecessary dummy variables that won't add value to the model. So let's boil it down to diet type without the nuance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, subset=['diet'], inplace=True)\n",
    "df['vegetarian'] = df['diet'].apply(lambda x: 1 if (\"vegetarian\" in x) or (\"vegan\" in x) else 0)\n",
    "df.drop(\"diet\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse spoken languages\n",
    "\n",
    "The same goes for the `language` variable. There are 3 modifiers for a multitude of languages. The permutation between all possible values will generate thousands of unnecessary columns. Let's just keep the languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                            english\n",
       "1                           english, spanish, french\n",
       "2                               english, french, c++\n",
       "3                                    english, german\n",
       "5                                   english, chinese\n",
       "                            ...                     \n",
       "59936                               english, chinese\n",
       "59937                               english, spanish\n",
       "59942                                        english\n",
       "59943                                        english\n",
       "59944    english, spanish, chinese, korean, japanese\n",
       "Name: speaks, Length: 35551, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['speaks'].replace([\" \\(fluently\\)\", \" \\(okay\\)\", \" \\(poorly\\)\"], \"\", regex=True, inplace=True)\n",
    "df[\"speaks\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But filtering out the language modifiers isn't enough. There's only one column for all the user's spoken languages, whose combination might generate a dozen thousands dummy variables. Therefore, each `speaks` value should be parsed and gain a dummy variable of its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_to_dummies(df, column):\n",
    "    \"\"\"\n",
    "    Transforms a column with comma-separated values into new 0-or-1 columns.\n",
    "    \"\"\"\n",
    "    expanded_values = df[column].str.split(pat=\", \", expand=True)\n",
    "    # see https://stackoverflow.com/questions/26977076/pandas-unique-values-multiple-columns \n",
    "    unique_labels = pd.unique(expanded_values.values.ravel('K'))\n",
    "    for label in unique_labels:\n",
    "        if label == None:\n",
    "            label = \"None\"\n",
    "        df[f\"{column}_{label}\"] = df[column].apply(lambda x: 1 if label in x else 0)\n",
    "    df.drop(column, axis=1, inplace=True)\n",
    "    df.drop(f\"{column}_None\", axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "df.dropna(axis=0, subset=[\"speaks\"], inplace=True)\n",
    "df = parse_to_dummies(df, column=\"speaks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert \"drink\" values into a numerical scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-367c87717e5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m df['drinks'].replace({\"not at all\": 0,\n\u001b[0m\u001b[1;32m      2\u001b[0m                      \u001b[0;34m\"rarely\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                      \u001b[0;34m\"socially\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                      \u001b[0;34m\"often\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                      \u001b[0;34m\"very often\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4295\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4296\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4297\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4299\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "df['drinks'].replace({\"not at all\": 0,\n",
    "                     \"rarely\": 1,\n",
    "                     \"socially\": 2,\n",
    "                     \"often\": 3,\n",
    "                     \"very often\": 4,\n",
    "                     \"desperately\": 5}, inplace=True)\n",
    "df['drinks']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract offspring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['offspring'].replace(['doesn&rsquo;t have kids',\n",
    "                         'doesn&rsquo;t have kids, and doesn&rsquo;t want any',\n",
    "                         'doesn&rsquo;t have kids, but might want them',\n",
    "                         'doesn&rsquo;t have kids, but wants them',\n",
    "                         'might want kids',\n",
    "                         'doesn&rsquo;t want kids',\n",
    "                         'wants kids'], 0, inplace=True)\n",
    "\n",
    "df['offspring'].replace(['has a kid',\n",
    "                         'has a kid, and might want more',\n",
    "                         'has a kid, and wants more',\n",
    "                         'has a kid, but doesn&rsquo;t want more',\n",
    "                         'has kids',\n",
    "                         'has kids, and might want more',\n",
    "                         'has kids, and wants more',\n",
    "                         'has kids, but doesn&rsquo;t want more',], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract ethnicities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, subset=['ethnicity'], inplace=True)\n",
    "df = parse_to_dummies(df, column=\"ethnicity\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up religion\n",
    "\n",
    "Let's remove the religion variable modifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['religion'].replace([\" and laughing about it\",\n",
    "                       \" somewhat serious about it\",\n",
    "                       \" and very serious about it\",\n",
    "                       \" but not too serious about it\"], \"\", regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['religion']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract pet information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pets\"].fillna(\"Unknown\", inplace=True)\n",
    "df['dog_person'] = df['pets'].apply(lambda x: 1 if (\"has dogs\" in x) or (\"likes dogs\" in x) else 0)\n",
    "df['cat_person'] = df['pets'].apply(lambda x: 1 if (\"has cats\" in x) or (\"likes cats\" in x) else 0)\n",
    "df.drop('pets', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dummy variables from categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy(df):\n",
    "    \"\"\"\n",
    "    Creates dummy variables for all the categorial variables in a DataFrame and concatenates it\n",
    "    with the original numerical columns.\n",
    "    Input: pandas DataFrame\n",
    "    Output: pandas DataFrame\n",
    "    \"\"\"\n",
    "    cat_cols = df.select_dtypes(include=\"object\").columns\n",
    "    num_cols = df.select_dtypes(exclude=\"object\").columns\n",
    "    dummy_df = pd.get_dummies(df[cat_cols],\n",
    "                              prefix=cat_cols,\n",
    "                              prefix_sep=\"_\",\n",
    "                              dummy_na=True,\n",
    "                              columns=cat_cols)\n",
    "                              \n",
    "    df_new = pd.concat([df[num_cols], dummy_df], axis=1)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_dummy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_table = df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diet_vegetarian'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
